#+LATEX_CLASS: assignment 
#+TITLE: Challenge Report
#+AUTHOR: Mozhdeh, Naghmeh, Rozita, Samim
#+OPTIONS: toc:nil
#+PROPERTY: header-args:R  :session *R* :tangle yes
#+PROPERTY: results output
#+DATE: January 2015

#+BEGIN_ABSTRACT
In this report we tried to find a model to fit the Kaggle competition for Avazu Click-Through rate prediction.
First we explain how to load the data and what attributes to choose for building models. Then we built a number of
models and evaluated them. In the end we found that the Naïve Bayes is the best model that fits our data.
#+END_ABSTRACT

* Loading data into R
We took the first 5000 records of the original data as a CSV file and read it into
R.

#+BEGIN_SRC R
ds = read.csv("new_train.csv")
#+END_SRC

Here we correct data types
and set train and test data sets as discussed.

#+BEGIN_SRC R
ds[] <- lapply(ds, factor)
## Correcting click values
ds$click <- as.integer(ds$click)
ds[ds$click==1,c('click')] <- 0
ds[ds$click==2,c('click')] <- 1
target <- "click"
train <- c(1:4000)
test <- c(4001:5000)
#+END_SRC

#+RESULTS:

After some inspection we found that we can ignore some attributes. =hour= attribute is
constant in this portion of data.

#+BEGIN_SRC R
summary(ds$hour)

:     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
: 14100000 14100000 14100000 14100000 14100000 14100000
#+END_SRC

#+RESULTS:
: 14102100 
:     5000

Therefore we decided to ignore =hour= attribute.

* GBM
We used /Gradient Boosting/ to build a sense of how important
each attribute is so that we can ignore it in our models. Before using gradient
boosting we ignore =device_ip= and =id=, as we concluded that they
are not relevant to the target variable. This model were evaluated
using the 5000-record data.

#+BEGIN_SRC R
ignore <- c(
    "id",
    "device_ip"
    ) # Coloumns to ignore
vars <- setdiff(names(ds), ignore)
inputs <- setdiff(vars, target)
form <- formula(paste(target, "~ ."))
actual <- ds[test, target]
data <- ds[train,vars]
#+END_SRC

#+RESULTS:

Then we build our model by using =gbm= package.

#+BEGIN_SRC R
library(gbm)
GBM_model = gbm(
    form,data = data,
    n.trees = 10000, 
    distribution = "gaussian",
    cv.folds=2
    )
summary(GBM_model)

                              var     rel.inf
device_model         device_model 89.97205133
site_id                   site_id  5.73691195
C14                           C14  3.44807999
device_id               device_id  0.82271347
site_domain           site_domain  0.02024326
hour                         hour  0.00000000
C1                             C1  0.00000000
banner_pos             banner_pos  0.00000000
site_category       site_category  0.00000000
app_id                     app_id  0.00000000
app_domain             app_domain  0.00000000
app_category         app_category  0.00000000
device_type           device_type  0.00000000
device_conn_type device_conn_type  0.00000000
C15                           C15  0.00000000
C16                           C16  0.00000000
C17                           C17  0.00000000
C18                           C18  0.00000000
C19                           C19  0.00000000
C20                           C20  0.00000000
C21                           C21  0.00000000
#+END_SRC

#+RESULTS:
#+begin_example
 Warning message:
In gbm.fit(x, y, offset = offset, distribution = distribution, w = w,  :
  variable 1: hour has no variation.
                              var     rel.inf
device_model         device_model 89.97205133
site_id                   site_id  5.73691195
C14                           C14  3.44807999
device_id               device_id  0.82271347
site_domain           site_domain  0.02024326
hour                         hour  0.00000000
C1                             C1  0.00000000
banner_pos             banner_pos  0.00000000
site_category       site_category  0.00000000
app_id                     app_id  0.00000000
app_domain             app_domain  0.00000000
app_category         app_category  0.00000000
device_type           device_type  0.00000000
device_conn_type device_conn_type  0.00000000
C15                           C15  0.00000000
C16                           C16  0.00000000
C17                           C17  0.00000000
C18                           C18  0.00000000
C19                           C19  0.00000000
C20                           C20  0.00000000
C21                           C21  0.00000000
#+end_example

* Data Pre-processing
By looking at how important each attribute is, we decided to ignore 
less important attributes to make the models more accurate.

#+BEGIN_SRC R
ignore <- c(
    "hour", 
    "id",
    "device_ip",
    "C1",
    "banner_pos",
    "site_category",
    "app_domain",
    "app_category",
    "device_type",
    "device_conn_type",
    "C15",
    "C16",
    "C17",
    "C18",
    "C19",
    "C20",
    "C21"
    ) # Coloumns to ignore
vars <- setdiff(names(ds), ignore)
inputs <- setdiff(vars, target)
form <- formula(paste(target, "~ ."))
actual <- ds[test, target]
data <- ds[train,vars]
#+END_SRC

#+RESULTS:

Here is the structure of the data after data pre-processing.

#+BEGIN_SRC R
str(data)

'data.frame':	3500 obs. of  7 variables:
 $ click       : num  0 1 0 0 1 0 0 1 0 0 ...
 $ site_id     : Factor w/ 276 levels "02d5151c","030440fe",..: 32 32 153 ...
 $ site_domain : Factor w/ 234 levels "00e1b9c0","0150cc3e",..: 222 222 194 ...
 $ app_id      : Factor w/ 210 levels "00848fac","03528b27",..: 197 197 197 ...
 $ device_id   : Factor w/ 574 levels "004270bf","017c59a6",..: 395 395 395 ...
 $ device_model: Factor w/ 841 levels "00b08597","00b1f3a7",..: 315 394 17 ...
 $ C14         : Factor w/ 216 levels "375","377","380",..: 53 50 56 51 82 ...
#+END_SRC

#+RESULTS:
: 'data.frame':	3500 obs. of  7 variables:
:  $ click       : num  0 1 0 0 1 0 0 1 0 0 ...
:  $ site_id     : Factor w/ 276 levels "02d5151c","030440fe",..: 32 32 153 150 164 238 157 32 32 150 ...
:  $ site_domain : Factor w/ 234 levels "00e1b9c0","0150cc3e",..: 222 222 194 188 113 112 199 222 222 188 ...
:  $ app_id      : Factor w/ 210 levels "00848fac","03528b27",..: 197 197 197 39 197 197 197 197 197 210 ...
:  $ device_id   : Factor w/ 574 levels "004270bf","017c59a6",..: 395 395 395 68 395 395 124 395 395 377 ...
:  $ device_model: Factor w/ 841 levels "00b08597","00b1f3a7",..: 315 394 17 261 415 123 429 712 202 789 ...
:  $ C14         : Factor w/ 216 levels "375","377","380",..: 53 50 56 51 82 149 54 53 49 198 ...

Let us explore our data a little.
Displaying distribution of data based on site_category for all data and clicked data. 
For both all data and clicked data major site category is 28905ebd:

#+BEGIN_SRC R
table(ds$site_category)

0569f928 110ab22d 28905ebd 335d28a8 3e814130 50e219e0 72722551 75fa27f6 
      35        1     1909       57      604     1244       12       11 
76b2941d a818d37a bcf865d9 c0dd3be3 f028772b f66779e6 
     116        1        1        3      994       12
#+END_SRC

Displaying distribution of data based on app_category for all data and clicked data. For both all data and clicked data major app category is 07d7df22:

#+BEGIN_SRC R
table(ds$app_category)

 
 07d7df22 09481d60 0f2161f8 4ce2e9fc 75d80bbe 8ded1f7a cef3e649 d1327cf5 
     3955        1      751        4        6       66       70        5 
 f95efa07 fc6fa53d 
      141        1
#+END_SRC

* Loss Function
As Kaggle wanted, all the models and prediction should be evaluated against
the logarithmic loss function. 

After building our models we found out
that Kaggle wanted the prediction for every click as a probability. To be able to
have probabilities we should see our target variable as a numerical variable. But unfortunately
we built our data and model using our target variable as a binary variable. 
So we at first could not
calculate the logarithmic loss of our models. But
later we changed our models and used the =click= variable
as integer and predicted the probabilities of clicking
for each record.

This functions computes the logarithmic loss between two vectors.
It gets the vector of actual values and vector of
predicted values and returns the 
logarithmic loss between the actual and prediction vectors.

#+BEGIN_SRC R
## From http://git.io/FrTR
LogLoss <- function(actual, prediction) {
    epsilon <- .000000000000001
    yhat <- pmin(pmax(prediction, epsilon), 1-epsilon)
    logloss <- -mean(actual*log(yhat)
                    + (1-actual)*log(1 - yhat))
    return(logloss)
}
#+END_SRC

#+RESULTS:

* SVM
First we can use the =tune= function to determine our constants in using SVM.

#+BEGIN_SRC R
library(e1071)
tuned <- tune.svm(form, data = data, gamma = 10^(-6:-1), cost = 10^(1:2))
summary(tuned)

## Parameter tuning of ‘svm’:

## - sampling method: 10-fold cross validation 

## - best parameters:
##  gamma cost
##  1e-06   10
#+END_SRC

#+RESULTS:

Using the constants above we can train our model.

#+BEGIN_SRC R 
model  <- svm(form, data = data, gamma = 10^(-6:-1), cost = 10)
svmPred <- predict(model, ds[test,vars], type="raw")
svmPredVector <- unname(svmPred[as.character(test)])
#+END_SRC

Here is the logarithmic loss of this model.
Using LogLoss function we get:

#+BEGIN_SRC R
LogLoss(actual,svmPredVector)

: [1] 0.5206339
#+END_SRC
#+RESULTS:

* Naïve Bayes
#+BEGIN_SRC R
library(e1071) 
classifier <- naiveBayes(form, data=data)
predicted <- predict(classifier, ds[test, vars],type = "raw")
head(predicted[,2])

 [1] 0.003989185 0.016763740 0.005266338 0.337754577 0.189222685 0.210940868
#+END_SRC

#+RESULTS:
: [1] 0.003989185 0.016763740 0.005266338 0.337754577 0.189222685 0.210940868
: Error: unexpected '[' in " ["

Here is the logarithmic loss of this model.
Using LogLoss function we get:

#+BEGIN_SRC R
LogLoss(actual,predicted[,2])

: [1] 0.5724103
#+END_SRC

* kNN
#+BEGIN_SRC R
library(RWeka)
classifier <- IBk(form, data = data, control = Weka_control(K = 2, X = TRUE))
evaluate_Weka_classifier(classifier, numFolds = 10)

=== Summary ===

Correlation coefficient                  0.168 
Mean absolute error                      0.2574
Root mean squared error                  0.3948
Relative absolute error                 91.8172 %
Root relative squared error            105.4324 %
Total Number of Instances             4000
#+END_SRC

This model's error is too high.

#+RESULTS:
#+begin_example
=== 10 Fold Cross Validation ===

=== Summary ===

Correlation coefficient                  0.168 
Mean absolute error                      0.2574
Root mean squared error                  0.3948
Relative absolute error                 91.8172 %
Root relative squared error            105.4324 %
Total Number of Instances             4000
#+end_example

* Decision Tree
This model were evaluated using the 5000-record data and
click given as factor.

#+BEGIN_SRC R
library(party)
ctree <- ctree(form , data=data)
table(predict(ctree) , data$click)

        0    1
   0 2899  601 a b
   1    0    0 c d
#+END_SRC

These are the results of confusion matrix. It has a some how
good accuracy but a very low precision.

$$TP = d / (c+d) =  0$$
$$FP = b / (a+b) = 601 / (2899+601) = 0.17$$
$$TN = a / (a+b) = 2899 / (2899+601)=0.82 $$
$$FN = c / (c+d) = 0$$
$$AC=(a+d)/(a+b+c+d) = (2899+0)/(2899+601)=0.82$$
$$P = d / (b+d) = 0$$

* Loading More Data (4 Million Records)
We decided that this is not good portion of data and all of our models may be
wrong or inaccurate. So we took first four million records of data using =ff= package
of R. It took about half an hour to load the data.

#+BEGIN_SRC R
library(ff)
table <- read.csv.ffdf(file = 'train.csv', nrows = 4000000)
ds <- data.frame(table)
nobs <- nrow(ds)
train <- sample(nobs, 0.7*nobs)
test <- setdiff(seq_len(nobs), train)
#+END_SRC

#+RESULTS:
#+begin_example
Loading required package: bit
Attaching package bit
package:bit (c) 2008-2012 Jens Oehlschlaegel (GPL-2)
creators: bit bitwhich
coercion: as.logical as.integer as.bit as.bitwhich which
operator: ! & | xor != ==
querying: print length any all min max range sum summary
bit access: length<- [ [<- [[ [[<-
for more help type ?bit

Attaching package: ‘bit’

The following object is masked from ‘package:base’:

    xor

Attaching package ff
- getOption("fftempdir")=="/tmp/samim/Rtmp2kRNrM"

- getOption("ffextension")=="ff"

- getOption("ffdrop")==TRUE

- getOption("fffinonexit")==TRUE

- getOption("ffpagesize")==65536

- getOption("ffcaching")=="mmnoflush"  -- consider "ffeachflush" if your system stalls on large writes

- getOption("ffbatchbytes")==16777216 -- consider a different value for tuning your system

- getOption("ffmaxbytes")==536870912 -- consider a different value for tuning your system


Attaching package: ‘ff’

The following objects are masked from ‘package:bit’:

    clone, clone.default, clone.list

The following objects are masked from ‘package:utils’:

    write.csv, write.csv2

The following objects are masked from ‘package:base’:

    is.factor, is.ordered
#+end_example

Some of the models were so heavy that our computers could not
use them with so many records of data. Therefore some models were
evaluated using the 5000-records data, and some were
evaluated using the 4-million data.

We re-evaluated the Naïve Bayes model using this data, by
taking 70% of the data as our train data set.

#+BEGIN_SRC R
library(e1071) 
classifier <- naiveBayes(form, data=data)
predicted <- predict(classifier, ds[test, vars], type = "raw")
#+END_SRC

Here is the logarithmic loss of this model.
Using LogLoss function we get:

#+BEGIN_SRC R
LogLoss(actual,predicted[,2])

#+END_SRC

* Conclusion
The best model in these models were the Naïve Bayes model.
We choose this model as the best model based on its high accuracy and 
precision together. And also because of its good time costs of algorithms 
as we were able to build the model using our four-million-record data.

